\chapter{Ray Tracing}
Die Idee beim \introduce{Ray Tracing} ist es, für jeden Pixel, alle Objekte zu finden, die diesen Pixel beeinflussen.
Anhand all dieser Objekte wird die Pixelfarbe bestimmt.
Dazu wird vom Rückwärtslichttransport ausgegangen.
Man startet an der Kamera und sucht alle Pfade, auf denen das Licht dort hin gelangt.
Dabei wird angenommen, dass der Lichttransport den Gesetzen der geometrischen Optik folgt.

\section{Abtastung}
Ein \introduce{Rasterbild} ist eine äquidistante Abtastung eines Bildsignals.
Das Bildsignal wird also vereinfachend als stückweise konstante Funktion aufgefasst.
Die bringt Probleme wie \introduce{Aliasing} oder den \introduce{Moiré-Effekt} mit sich.

\begin{Theorem}[\textsc{Nyquist}-\textsc{Shannon}-Abtasttheorem]
	Ein kontinuierliches, bandbegrenztes Signal mit einer maximalen Frequenz $f_{max}$ muss mit einer Frequenz echt größer als $2 f_{max}$ abgetastet werden, damit aus dem diskreten Signal das Ursprungssignal exakt rekostruiert werden kann.
\end{Theorem}

Ist die Abtastfrequenz zu gering, kommt es zu Aliasing.
Ein möglicher Lösungsansatz ist eine Vorfilterung des Signals, bei der hohe Frequenzen entfernt werden.
Dies ist jedoch im allgemeinen Fall nicht möglich.
Eine andere Möglichkeit ist eine \introduce{Überabtastung} mit anschließender Filterung.

\section{Lochkamera}
Am einfachsten zur Bildsynthese ist das Modell der Lochkamera.
Sie ist definiert durch die Position ihrer Öffnung und der Bildebene.
Da keine Linse verwendet wird, hat sie unbeschränkte Schärfentiefe.

Eine \introduce{virtuelle Kamera} ist definiert durch ihre Position und Blickrichtung, sowie die Orientierung der Vertikalen Achse.
Dazu die Breite und Höhe der Bildebene und ihr Abstand \emph{vor} der Kamera.

Bei der Bildsynthese kann \introduce{objektbasiert} oder \introduce{bildbasiert} vorgegangen werden.

Beim objektbasierten Rendern werden für jedes Objekt alle Pixel bestimmt, die es überdeckt.
Dann wird die Farbe dieser Pixel ermittelt.

Beim bildbasierten Rendern werden für jeden Pixel alle an dieser Stelle sichtbaren Objekte bestimmt.
Daraus wird die Pixelfarbe ermittelt.

\section{Whitted-Style Ray Tracing}
Ray Tracing besteht aus drei Schritten, die in dieser Reihenfolge ausgeführt werden.
\begin{enumerate}
	\item \introduce{Ray Generation} Für jeden Pixel wird ein Strahl von der Kamera durch diesen Pixel erzeugt.
	\item \introduce{Ray Intersection} Für jeden Strahl wird das Objekt gefunden, das die Kamera an diesem Pixel sieht.
	Es ist das Objekt, das diesen Strahl schneidet und dessen Schnittpunkt am nächsten an der Kamera liegt.
	\item \introduce{Beleuchtungsberechnung} Farbe und Schattierung dieses Objekts an dieser Stelle wird berechnet.
	Dazu können rekursiv weitere Strahlen erzeugt werden, um \zB reflektierende Oberflächen darzustellen.
\end{enumerate}

\section{Ray Generation}
Die virtuelle Kamera ist definiert durch ihr Projektionszentrum $e$ (engl. eye) und einen $up$-Vektor mit $\norm{up} = 1$.
Sei $z$ der Zielpunkt eines Strahls.
Definiere dann
\[
	w = \frac{(e - z)}{\norm{e - z}} \text{,} \qquad
	u = up \times w \text {,} \qquad
	v = w \times u \text{.}
\]
Dabei ist $w$ die negative Blickrichtung.

Die Bildebene ist gegeben durch ihren Abstand $d$ zur Kamera, ihren linken und rechten Rand $l$ und $r$ sowie ihren oberen und unteren Rand $b$ und $t$.
Strahlen von $e$ aus zu einem Punkt $s$ auf der Bildebene sind nun beschrieben durch:
\[
	s = \lambda_1 u + \lambda_2 v - dw \qquad \lambda_1 \in [l, r] \quad \lambda_2 \in [b, t] 
\]
Typischerweise ist das Sichtfeld symmetrisch, es gilt also $l = -r$ und $t = -b$.
Das Verhältnis aus der Breite zur Höhe des Bildschirms heißt \introduce{Aspect Ratio}.

\section{Ray Intersection}
Geometrische Objekte können auf drei verschiedene Arten beschrieben werden:
\begin{itemize}
	\item \introduce{Parameterdarstellung}
	Einsetzen aller gültigen Parameterwerte liefert alle Punkte des Objekts.
	\item \introduce{Explizite Darstellung}
	Es ist eine Funktion gegeben, die an jeder Position beschreibt, ob das Objekt an dieser Position ist.
	\item \introduce{Implizite Darstellung}
	Alle Punkte des Objekts bilden die Lösungsmenge eines Systems von Gleichungen.
\end{itemize}

\subsection{Kugelschnitt}
Alle Punkte auf der Kugeloberfläche $K$ haben Abstand $r$ vom Mittelpunkt $c = (c_x, c_y, c_z)$.
Die implizite Darstellung der Kugel ist
\[
	K = \{(x, y, z) \mid \norm{(x - c_x, y - c_y, z - c_z)} = r\} \text{.}
\]
Sei $r(t) = e + td$ ein mit $t \in \mathbb{R}_+$ parametriesierter Strahl.
Für den Schnittpunkt aus Kugel und Strahl ergibt sich:
\begin{align*}
	0 &= \norm{r(t) - c}^2 - r^2 \\
		&= \norm{e + td - c}^2 - r^2 \\
		&= \dotproduct{e + td - c}{e + td - c} - r^2 \\
		&= \underbrace{\dotproduct{e - c}{e - c} - r^2}_c + \underbrace{2 \dotproduct{td}{e - c}}_{b \cdot t} + \underbrace{t^2 \dotproduct{d}{d}}_{a \cdot t^2}
\end{align*}
Mit der Mitternachtsformel
\[
	t_{1,2} = \frac{-b \pm \sqrt{b^2 - 4ac}}{2a}
\]
lassen sich nun die Parameter $t_1$ und $t_2$ bestimmen.
\[
	D = b^2 - 4ac
\]
heißt ist die Diskriminante.
Ist $D < 0$, gibt es keinen Schnittpunkt.
Ist sie gleich $0$, gibt es genau einen Schnittpunkt bei $r(t_1) = r(t_2)$.
Ist $D$ positiv, gibt es bei $r(t_1)$ und $r(t_2)$ jeweils einen Schnittpunkt.
Die Parameter $t_1$ und $t_2$ können kleiner als $0$ sein.
In diesem Fall liegt der Schnittpunkt hinter der Kamera und sollte nicht betrachtet werden.

\subsection{Ebenenschnitt}
Eine Ebene im $\mathbb{R}^3$ hat die implizite Darstellung
\[
	E = \{(x, y, z) \mid ax + by + cz + d = 0, \quad
	a, b, c, d \in \mathbb{R}, \quad
	a, b, c, \neq 0\} \text{.}
\]
Mit zwei nicht kollinearen Vektoren in der Ebene lässt sich die Normale $n$ berechnen.
Sei $r(t) = e + td$ ein Strahl mit $\norm{d} = 1$.
Dazu sei $\dotproduct{x}{n} - d = 0$ mit $\norm{n}$ die Ebene in Hesse-Normalform.
\begin{align*}
	0 &= \dotproduct{e + td}{n} - d \\
	  &= \dotproduct{e}{n} + t \dotproduct{d}{n} - d
\end{align*}
Damit folgt für den Parameter $t$:
\[
	t = \frac{d - \dotproduct{e}{n}}{\dotproduct{d}{n}}
\]
Fall $\dotproduct{d}{n} = 0$ gilt, sind Strahl und Ebene parallel und es exitiert kein Schnittpunkt.
Andernfalls schneiden sich Strahl und Ebene im Punkt $r(t)$.
Wenn $t < 0$ ist, liegt der Schnittpunkt hinter der Kamera und sollte ignoriert werden.

\subsection{Dreiecksschnitt}
Um einen Schintt zwischen einem Strahl und einem Dreieck zu berechnen, muss zuerst ein Schnittpunkt des Strahl mit der vom Dreieck aufgespannten Ebene gefunden werden.
Die Koordianten des Schnittpunktes können dann in baryzentrische Koordinaten überführt und auf Positivität überprüft werden.

\section{Beleuchtungsberechnung}
Beleuchtung ist essentiell für einen dreidimensionalen Eindruck.
Ein wichtiger Teil der Beleuchtungsberechungen ist die \introduce{Reflexion}.
Es gibt zwei Extreme.
Bei der \introduce{spekularen Reflexion} wird das Licht nur anhand eines Strahls reflektiert, wobei Einfallswinkel gleich Ausfallswinkel gilt.
Dagegen wird das Licht bei der \introduce{diffusen/lambterschen Reflexion} zu gleichen Teilen in alle Richtungen gestreut.

Im Folgenden wird nur Reflexion an der Oberfläche von Objekten behandelt.

\subsection{Bidirectional Reflectance Distribution Function - BRDF}
Eine \introduce{BRDF (Bidirectional Reflectance Distribution Function)} ist ein radiometrisches Konzept, um die Reflexion an einem Oberflächenpunkt zu beschreiben.
Sie gibt das Verhältnis von ausgehendem zu einfallendem Licht an einem Oberflächenpunkt an.
Um Materialien abzubilden, muss die BRDF erst aufwendig an diesem Material gemessen werden.

\subsection{Phong-Beleuchtungsmodell}
Das \introduce{Phong-Beleuchtungsmodell} ist ein phänomenologisches (also physikalische nicht korrektes) Modell zur Darstellung der Reflexion, anhand von drei Komponenten, die von den Materialparametern $k_a$, $k_d$ und $k_s$ sowie dem Phong-Exponenten $n$ abhängen:
\begin{itemize}
	\item \introduce{Ambient}
	Die indirekte Beleuchtung, also Licht, das von anderen Oberflächen reflektiert wird.
	Es ergibt sich der Anteil $I_a = k_a \cdot I_L$.
	\item \introduce{Diffus}
	Der Anteil der lambertschen Reflexion.
	Für den diffusen Anteil ergibt sich $I_d = k_d \cdot I_L \cdot \cos \theta = k_d \cdot I_L \cdot \dotproduct{N}{L}$.
	Dabei ist $I_L$ die Intensität der Lichtquelle, $N$ die normierte Normale am Oberflächenpunkt und $L$ der normierte Vektor zur Lichtquelle.
	\item \introduce{Spekular}
	Spekulare Reflexion bzw. perfekte Spiegelung.
	Die spekulare Reflexion findet ausschließlich in Richtung $R_L$ statt.
	Der Vektor $R_L$ ist die Spiegelung des Vektors $L$ zur Lichtquelle an der Oberflächennormalen $N$.
	Sind alle Vektoren normiert, ergibt sich $R_L = 2N \cdot \dotproduct{N}{L} - L$.

	Durch gerichtete Reflexion entstehen Glanzlichter.
	Die Stärke der Spiegelung fällt für von $R_L$ verschiedene Richtungen stark ab.
	Der Abfall wird durch $\cos^n \alpha$ modelliert.
	Der spekulare Anteil ergibt sich damit zu $I_s = k_s \cdot I_L \cdot \cos^n \alpha = k_s \cdot I_L \cdot \dotproduct{R_L}{V}^n$.
\end{itemize}
Die Gesamtbeleuchtung ergibt sich durch
\begin{align*}
	I &= I_a + I_d + I_s \\
	  &= k_a \cdot I_L +
	  	 k_d \cdot I_L \cdot \dotproduct{N}{L} +
	  	 k_s \cdot I_L \cdot \dotproduct{R_L}{V}^n \text{.}
	\end{align*}
Die Reflexionskoeffizienten $k_a$, $k_d$ und $k_s$ sind theoretisch Wellenlängenabhängig und werden deshalb oft für drei Wellenlängen (rot, grün, blau) angegeben.

Diffuse Reflexionen haben meist die Farbe der Oberfläche.
Spekulare Reflexionen haben meist die Farbe der Oberfläche, wenn es sich um Metalle handelt.
Ansonsten oft die Farbe der Lichtquelle.

Bei der Berechnung der Beleuchtungen ist man nur an den Richtungen interessiert, für die die Skalarprodukte positiv sind.

Optional kann das Phong-Beleuchtungsmodell um einen Emmisionsterm ersetzt werden.

\subsection{Beleuchtung von Dreiecksnetzen}
Bei den Beleuchtungsberechnungen im Phong-Beleuchtungsmodell wird an mehreren Stellen die Oberflächennormale verwendet.
Beim sog. \introduce{Flat Shading} wird dazu die Dreiecksnormale verwendet.
Nachteil dabei ist, dass die Kanten des Dreiecksnetzes deutlich sichtbar werden.
Die Illision einer glatten, gekürmmten Oberfläche erreicht man, indem man die \introduce{Vertex-Normalen} betrachtet und über die Dreicksfläche interpoliert werden.
Die Vertex-Normale berechnet sich als gewichtetes Mittel der Normalen der angrenzenden Dreiecke.
Die Normale eines Dreiecks kann mit dem Kreuzprodukt bestimmt werden.
Die so erlangte Vertex-Normale muss normalisiert werden.
Es darf nicht einfach stattdessen durch die Anzahl der angrenzenden Normalen geteilt werden.

Nun wird aber jede Kante weich gezeichnet.
Ist der Winkel zwischen zwei benachbarten Dreicken groß, benötigt man mehrere Normalen.
Aus diesem Grund speichert man bei Dreiecksnetzen in der Regel drei Eckpunkte und drei Normalen.

Die Interpolation der Normalen wird linear und komponentenweise anhand der baryzentrischen Koordinaten durchgeführt.
Beleuchtungsberechungen mit der interpolierten Normalen nennt man \introduce{Phong-Shading}.

\section{Lichtquellen}
Es gibt verschiedene Lichtquellen mit unterschiedlichen Eigenschaften.
Eine \introduce{Punktlichtquelle} ist definiert durch ihre Position und Intensität.
Die Intensität fällt mit dem Abstandsquadrat.

\introduce{Paralleles Licht} ist definiert durch seine Richtung und die Flussdichte.
Sonnenlicht ist nahezu parallel.

Bei einem \introduce{Strahler/Spotlight} gibt es einen Lichtkegel.
Die Intensität bei Winkel $\theta$ beträgt $\cos^n \theta$.

Bei \introduce{Flächenlichtquellen} strahlt eine Fläche.
Reale Lichtquellen sind (fast) immer Flächenlichtquellen.
Sie sind der Grund für weiche Schatten.

\section{Schatten, Reflexion, Brechung}
Betrachtet man ausschließlich die Schnittpunkte mit den Primärstrahlen, wird eine Oberfläche genau dann beleuchtet, wenn sie der Kamera zugewandt ist.
Dabei wird vernachlässigt, dass andere Objekte der Szene Schatten werfen können.
Aus diesem Grund werden vom Schnittpunkt aus \introduce{Schattenstrahlen/Sekundärstrahlen} zu allen Lichtquelles ausgesendet und getestet, ob diese ein andere Objekte schneiden.
Wegen der begrenzten Genauigkeit von Fließkommazahlen, kann es sein, dass der Schattenstrahl das Objekt, an dem er startet, erneut schneidet.
Bei konvexen Objekten reicht es zu testen, dass nicht das gleiche Objekt erneut geschnitten wird.
Ansonsten kann der Strahl \zB mit einem kleinen Abstand zum Schnittpunkt gestartet werden.

Neben den Schattenstrahlen gibt es auch noch \introduce{Reflexionsstrahlen} und \introduce{Transmissionsstrahlen}.
Ein solcher kann genauso behandelt werden, wie ein Sichtstrahl.
Durch rekursive Verfolgung von Mehrfachreflexion/-transmission, können weitere Sekundärstrahlen entstehen.
Die für den Strahl berechnete Farbe wird mit einem weiteren Koeffizienten $k_r$/$k_t$ in die Beleuchtung mit eingerechnet.

Die Rekursion kann dabei theoretisch beliebig tief gehen.
Eine Möglichkeit ist eine feste Rekursionsgrenze.
Alternativ, kann abgebrochen werden, wenn Beitrag zur Farbe vernachlässigbar klein wird.

Die Reflexion folgt dabei dem Prinzip Einfallswinkel gleich Ausfallswinkel.
Bei der Brechung muss das Snellsche Gesetz benutzt werden, um die Richtung des Strahls zu ermitteln.

\subsection{Snellsches Brechungsgesetz}
Das \introduce{Snellsche Brechungsgesetz} beschreibt die Richtungsänderung einer Welle, beim Übergang von einem Medium in eines mit anderer Brechzahl.
Da sich Licht in verschiedenen Medien unterschiedlich schnell bewegt, definiert sich die \introduce{(reele) Brechzahl} $\eta$ als
\[
	\eta = \frac{c_0}{c_\eta} \text{.}
\]
Dabei ist $c_0$ die Lichtgeschwindigkeit im Vakuum und $c_\eta$ die Lichtgeschwindigkeit im betrachteten Medium.
Die Brechzahl ist dabei in der Regel wellenlängenabhängig.
Unter \introduce{Dispersion} versteht man die Abhöngigkeit der Brechzahl von unterschiedlichen Wellenlängen.

\begin{Theorem}[Snellsches Brechungsgesetzt]
	Sei $\eta_i$ die Brechzahl das Eingangsmediums und $\eta_t$ die Brechzahl des Mediums in das eingedrungen wird.
	$\theta_i$ ist der Einfallswinkel, $\theta_t$ der Winkel zum Lot im Medium.
	\[
		\eta_i \cdot \sin \theta_i = \eta_t \cdot \sin \theta_t
	\]
\end{Theorem}

Die Brechung findet dabei beim Übergang ins optisch dichtere Medium zum Lot hin statt.
Der \introduce{Fresnel-Effekt} beschreibt die Verteilung der Strahldichte zwischen Reflexion und Transmission.
Der \introduce{Transmissionsvektor} $T$ ergibt sich durch
\[
	T = - \frac{\eta_i}{\eta_t} I +
	\left(
		\frac{\eta_i}{\eta_t} \cdot \cos \theta_i -
		\sqrt{1 - \left(\frac{\eta_i}{\eta_t}\right)^2 \cdot \left(1 - \cos^2 \theta_i\right)}
	\right)N \text{.}
\]

\section{Anti-Aliasing}
Unter \introduce{Anti-Aliasing} versteht man, Aliasingeffektie zu reduzieren.
Als Technik dafür bietet sich das Überabtasten (Supersampling).
Beim \introduce{uniformen Supersampling} werden gleichmäßig mehrere Samples pro Pixel genommen.
Dabei muss der Abstand zwischen den Samples immer gleich sein.

Beim \introduce{adaptiven Supersampling} unterteilt man einen Pixel in Samples, wenn die Differenz der Farbe zum Nachbarpixel zu groß ist.
Dieses Verfahren kann rekursiv fortgesetzt werden.
Adaptives Supersampling wird heute kaum noch verwendet.

Auch \introduce{stochastisches Sampling} ist möglich.
Dabei werden mehrere Samples pro Pixel an zufälligen Stellen gemacht.
Beim \introduce{Stratified Sampling} wird der Pixel zuerst in ein Gitter unterteilt, dann wird in jeder Zelle an einer zufälligen Stelle abgetastet.

Nicht-uniformes Abtasten veringert das Aliasing aber erhöht das Rauschen.
Rauschen wird jedoch vom menschlichen Auge als weit weniger störend empfunden.

\section{Distributed Ray Tracing}
Beim Whitted-Style ray Tracing sehen die Bilder oft zu perfekt aus:
\begin{itemize}
	\item Perfekte Spiegelung und Reflexion.
	\item Keine weichen Schattenkanten.
	\item Unendliche Schärfentiefe.
	\item Keine Bewegungsunschärfe.
\end{itemize}
Beim \introduce{Distributed Ray Tracing} werden $n$ Schattenstrahlen zu zufälligen Punkten auf der Lichtquelle geschickt.
Da reale Lichtquellen endliche Ausdehnung haben, führt dies zu weichen Schatten.

Für Bewegungunschärfe können die $n$ Strahlen zu leicht unterschiedlichen Zeiten verschickt werden.
Dies simuliert die Belichtungszeit bei realen Kameras.

Für Schärfentiefe müssen die $n$ Strahlen durch eine simulerte Linse gebrochen werden.
