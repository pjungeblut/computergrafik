\chapter{Ray Tracing}
Die Idee beim \introduce{Ray Tracing} ist es, für jeden Pixel, alle Objekte zu finden, die diesen Pixel beeinflussen.
Anhand all dieser Objekte wird die Pixelfarbe bestimmt.
Dazu wird vom Rückwärtslichttransport ausgegangen.
Man startet an der Kamera und sucht alle Pfade, auf denen das Licht dort hin gelangt.
Dabei wird angenommen, dass der Lichttransport den Gesetzen der geometrischen Optik folgt.

\section{Abtastung}
Ein \introduce{Rasterbild} ist eine äquidistante Abtastung eines Bildsignals.
Das Bildsignal wird also vereinfachend als stückweise konstante Funktion aufgefasst.
Die bringt Probleme wie \introduce{Aliasing} oder den \introduce{Moiré-Effekt} mit sich.

\begin{Theorem}[\textsc{Nyquist}-\textsc{Shannon}-Abtasttheorem]
	Ein kontinuierliches, bandbegrenztes Signal mit einer maximalen Frequenz $f_{max}$ muss mit einer Frequenz echt größer als $2 f_{max}$ abgetastet werden, damit aus dem diskreten Signal das Ursprungssignal exakt rekostruiert werden kann.
\end{Theorem}

Ist die Abtastfrequenz zu gering, kommt es zu Aliasing.
Ein möglicher Lösungsansatz ist eine Vorfilterung des Signals, bei der hohe Frequenzen entfernt werden.
Dies ist jedoch im allgemeinen Fall nicht möglich.
Eine andere Möglichkeit ist eine \introduce{Überabtastung} mit anschließender Filterung.

\section{Lochkamera}
Am einfachsten zur Bildsynthese ist das Modell der Lochkamera.
Sie ist definiert durch die Position ihrer Öffnung und der Bildebene.
Da keine Linse verwendet wird, hat sie unbeschränkte Schärfentiefe.

Eine \introduce{virtuelle Kamera} ist definiert durch ihre Position und Blickrichtung, sowie die Orientierung der Vertikalen Achse.
Dazu die Breite und Höhe der Bildebene und ihr Abstand \emph{vor} der Kamera.

Bei der Bildsynthese kann \introduce{objektbasiert} oder \introduce{bildbasiert} vorgegangen werden.

Beim objektbasierten Rendern werden für jedes Objekt alle Pixel bestimmt, die es überdeckt.
Dann wird die Farbe dieser Pixel ermittelt.

Beim bildbasierten Rendern werden für jeden Pixel alle an dieser Stelle sichtbaren Objekte bestimmt.
Daraus wird die Pixelfarbe ermittelt.

\section{Ray Tracing}
Ray Tracing besteht aus drei Schritten, die in dieser Reihenfolge ausgeführt werden.
\begin{enumerate}
	\item \introduce{Ray Generation} Für jeden Pixel wird ein Strahl von der Kamera durch diesen Pixel erzeugt.
	\item \introduce{Ray Intersection} Für jeden Strahl wird das Objekt gefunden, das die Kamera an diesem Pixel sieht.
	Es ist das Objekt, das diesen Strahl schneidet und dessen Schnittpunkt am nächsten an der Kamera liegt.
	\item \introduce{Shading} Farbe und Schattierung dieses Objekts an dieser Stelle wird berechnet.
	Dazu können rekursiv weitere Strahlen erzeugt werden, um \zB reflektierende Oberflächen darzustellen.
\end{enumerate}

\section{Ray Generation}
Die virtuelle Kamera ist definiert durch ihr Projektionszentrum $e$ (engl. eye) und einen $up$-Vektor mit $\norm{up} = 1$.
Sei $z$ der Zielpunkt eines Strahls.
Definiere dann
\[
	w = \frac{(e - z)}{\norm{e - z}} \text{,} \qquad
	u = up \times w \text {,} \qquad
	v = w \times u \text{.}
\]
Dabei ist $w$ die negative Blickrichtung.

Die Bildebene ist gegeben durch ihren Abstand $d$ zur Kamera, ihren linken und rechten Rand $l$ und $r$ sowie ihren oberen und unteren Rand $b$ und $t$.
Strahlen von $e$ aus zu einem Punkt $s$ auf der Bildebene sind nun beschrieben durch:
\[
	s = \lambda_1 u + \lambda_2 v - dw \qquad \lambda_1 \in [l, r] \quad \lambda_2 \in [b, t] 
\]
Typischerweise ist das Sichtfeld symmetrisch, es gilt also $l = -r$ und $t = -b$.
Das Verhältnis aus der Breite zur Höhe des Bildschirms heißt \introduce{Aspect Ratio}.

\section{Ray Intersection}
Geometrische Objekte können auf drei verschiedene Arten beschrieben werden:
\begin{itemize}
	\item \introduce{Parameterdarstellung}
	Einsetzen aller gültigen Parameterwerte liefert alle Punkte des Objekts.
	\item \introduce{Explizite Darstellung}
	Es ist eine Funktion gegeben, die an jeder Position beschreibt, ob das Objekt an dieser Position ist.
	\item \introduce{Implizite Darstellung}
	Alle Punkte des Objekts bilden die Lösungsmenge eines Systems von Gleichungen.
\end{itemize}

\subsection{Kugelschnitt}
Alle Punkte auf der Kugeloberfläche $K$ haben Abstand $r$ vom Mittelpunkt $c = (c_x, c_y, c_z)$.
Die implizite Darstellung der Kugel ist
\[
	K = \{(x, y, z) \mid \norm{(x - c_x, y - c_y, z - c_z)} = r\} \text{.}
\]
Sei $r(t) = e + td$ ein mit $t \in \mathbb{R}_+$ parametriesierter Strahl.
Für den Schnittpunkt aus Kugel und Strahl ergibt sich:
\begin{align*}
	0 &= \norm{r(t) - c}^2 - r^2 \\
		&= \norm{e + td - c}^2 - r^2 \\
		&= \dotproduct{e + td - c}{e + td - c} - r^2 \\
		&= \underbrace{\dotproduct{e - c}{e - c} - r^2}_c + \underbrace{2 \dotproduct{td}{e - c}}_{b \cdot t} + \underbrace{t^2 \dotproduct{d}{d}}_{a \cdot t^2}
\end{align*}
Mit der Mitternachtsformel
\[
	t_{1,2} = \frac{-b \pm \sqrt{b^2 - 4ac}}{2a}
\]
lassen sich nun die Parameter $t_1$ und $t_2$ bestimmen.
\[
	D = b^2 - 4ac
\]
heißt ist die Diskriminante.
Ist $D < 0$, gibt es keinen Schnittpunkt.
Ist sie gleich $0$, gibt es genau einen Schnittpunkt bei $r(t_1) = r(t_2)$.
Ist $D$ positiv, gibt es bei $r(t_1)$ und $r(t_2)$ jeweils einen Schnittpunkt.
Die Parameter $t_1$ und $t_2$ können kleiner als $0$ sein.
In diesem Fall liegt der Schnittpunkt hinter der Kamera und sollte nicht betrachtet werden.

\subsection{Ebenenschnitt}
Eine Ebene im $\mathbb{R}^3$ hat die implizite Darstellung
\[
	E = \{(x, y, z) \mid ax + by + cz + d = 0, \quad
	a, b, c, d \in \mathbb{R}, \quad
	a, b, c, \neq 0\} \text{.}
\]
Mit zwei nicht kollinearen Vektoren in der Ebene lässt sich die Normale $n$ berechnen.
Sei $r(t) = e + td$ ein Strahl mit $\norm{d} = 1$.
Dazu sei $\dotproduct{x}{n} - d = 0$ mit $\norm{n}$ die Ebene in Hesse-Normalform.
\begin{align*}
	0 &= \dotproduct{e + td}{n} - d \\
	  &= \dotproduct{e}{n} + t \dotproduct{d}{n} - d
\end{align*}
Damit folgt für den Parameter $t$:
\[
	t = \frac{d - \dotproduct{e}{n}}{\dotproduct{d}{n}}
\]
Fall $\dotproduct{d}{n} = 0$ gilt, sind Strahl und Ebene parallel und es exitiert kein Schnittpunkt.
Andernfalls schneiden sich Strahl und Ebene im Punkt $r(t)$.
Wenn $t < 0$ ist, liegt der Schnittpunkt hinter der Kamera und sollte ignoriert werden.

\subsection{Dreiecksschnitt}
Um einen Schintt zwischen einem Strahl und einem Dreieck zu berechnen, muss zuerst ein Schnittpunkt des Strahl mit der vom Dreieck aufgespannten Ebene gefunden werden.
Die Koordianten des Schnittpunktes können dann in baryzentrische Koordinaten überführt und auf Positivität überprüft werden.

\section{Shading}
